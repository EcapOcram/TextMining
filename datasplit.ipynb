{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import bs4 as bs\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the ticker list of the SP500 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.read_html(\n",
    "    'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "\n",
    "num_tickers = 500\n",
    "\n",
    "tickers = list(t_df[\"Symbol\"][0:num_tickers])\n",
    "\n",
    "#tickers = [\"TSLA\",  \"EBAY\", \"META\" ]   # for test\n",
    "#print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the titles of the articles and how long ago they were published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dct = { \"Name\": [\"Susan\", \"Mary\", \"Jon\", \"Pasquale\" ], \"Age\" : [89, 9, 33, 5]  }\n",
    "#test_df = pd.DataFrame(dct)\n",
    "#sorted_df = test_df.sort_values(by = [\"Age\"], ascending = True)\n",
    "#\n",
    "#sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sleep_time  = 5\n",
    "\n",
    "def extract_dates(parsed_doc):\n",
    "    from math import floor\n",
    "    today = datetime.datetime.now().date()\n",
    "    dates = parsed_doc.find_all('pubdate')\n",
    "    list_date = []\n",
    "    for date  in dates:\n",
    "        d = datetime.datetime.strptime( date.text, \"%a, %d %b %Y %H:%M:%S GMT\" )\n",
    "        list_date += [floor((today - d.date()).seconds / 1)]                          #.days\n",
    "    return list_date\n",
    "\n",
    "\n",
    "def get_titles(ticker, sleep_time, num_titles):\n",
    "    '''\n",
    "    This function return the url response from google news and parsed html for a stock ticker.\n",
    "    The time parameter is the sleep time before each request\n",
    "    '''\n",
    "    url = 'https://news.google.com/rss/search?hl=en-US&q='+ticker+'&gl=US&ceid=US:en'\n",
    "\n",
    "    time.sleep(sleep_time) ## wait 15 seconds between each request. This is SUPER IMPORTANT otherwise your IP-address will be banned for sending too frequent requests.\n",
    "\n",
    "    doc = urllib.request.urlopen(url).read()\n",
    "    parsed_doc = bs.BeautifulSoup(doc,'lxml')\n",
    "    titles = parsed_doc.find_all('title')[1:]\n",
    "    list_date = extract_dates(parsed_doc)                 # we  assume/have verified that the date are extracted in the same order as the titles\n",
    "    dct = {\"Ticker\": [ ticker ]*len(titles) , \"Titles\" : titles, \"Date\" : list_date}\n",
    "    title_df = pd.DataFrame(dct)\n",
    "    title_df = title_df.sort_values(by=\"Date\")\n",
    "    return title_df.iloc[0:num_titles]\n",
    "\n",
    "list_df = []                        #dictionary with input data\n",
    "num_articles = 10\n",
    "for ticker in tickers:\n",
    "    title = get_titles(ticker, sleep_time, num_articles)\n",
    "    list_df.append(title)\n",
    "    #print(title)\n",
    "\n",
    "#input_df = pd.DataFrame(dct.values(),index = tickers,columns=[\"Titles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = list_df[0]\n",
    "df.shape\n",
    "\n",
    "input_df = pd.concat(list_df)\n",
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_df[ input_df[\"Ticker\"] == \"EBAY\" ]\n",
    "#test_df = input_df\n",
    "#test_df[\"NEW\"] = [0]*test_df.shape[0]\n",
    "#test_df.loc[   test_df[\"Ticker\"] == \"EBAY\",\"NEW\"] = 1\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BRK.B: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for BRK.B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BF.B: No price data found, symbol may be delisted (period=1mo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for BF.B\n"
     ]
    }
   ],
   "source": [
    "sleep_time = 5\n",
    "threshold = 0.01\n",
    "\n",
    "def get_var_prc(ticker, sleep_time):\n",
    "    tickerData = yf.Ticker(ticker)\n",
    "    time.sleep(sleep_time)  # Wait between requests\n",
    "    df = tickerData.history()\n",
    "    if len(df) < 2:\n",
    "        print(f\"Insufficient data for {ticker}\")\n",
    "        return None\n",
    "    df['Change'] = df['Close'].diff()\n",
    "    return df[\"Change\"].iloc[-1] / df[\"Close\"].iloc[-2]  # Use iloc for integer indexing\n",
    "\n",
    "def get_target(x):\n",
    "    if x < -threshold:\n",
    "        return -1\n",
    "    elif abs(x) < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "# Add a new column 'Var_prc' and assign values to it\n",
    "for ticker in tickers:\n",
    "    var_prc = get_var_prc(ticker, sleep_time)\n",
    "    if var_prc is not None:  # Check if data is available\n",
    "        input_df.loc[input_df[\"Ticker\"] == ticker, 'Var_prc'] = var_prc\n",
    "        input_df.loc[input_df[\"Ticker\"] == ticker, 'Target'] = input_df[input_df[\"Ticker\"] == ticker]['Var_prc'].apply(get_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker                                             Titles  Date   Var_prc  \\\n",
      "66    YUM  [Yum China (YUMC) Q4 2023 Earnings Call Transc...     0  0.007726   \n",
      "65    YUM  [Yum Brands (YUM) Reports Next Week: Wall Stre...     0  0.007726   \n",
      "64    YUM  [Pizza Hut Announces Carl Loredo President of ...     0  0.007726   \n",
      "63    YUM  [Yum China (NYSE:YUMC) Misses Q1 Sales Targets...     0  0.007726   \n",
      "62    YUM  [Yum! Brands (YUM) Reports Earnings Tomorrow: ...     0  0.007726   \n",
      "\n",
      "    Target  \n",
      "66     0.0  \n",
      "65     0.0  \n",
      "64     0.0  \n",
      "63     0.0  \n",
      "62     0.0  \n"
     ]
    }
   ],
   "source": [
    "print(input_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://amaiya.github.io/ktrain/text/index.html#ktrain.text.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.to_csv(\"data_1005.csv\")\n",
    "input_df.to_csv(\"data_1005_2.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 uninstall yfinance -y\n",
    "#!pip3 install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10231\n"
     ]
    }
   ],
   "source": [
    "print(len(str(ls)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
